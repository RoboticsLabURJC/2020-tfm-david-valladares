## WEEK 3

### Color Filter Exercise

#### With WebRtc
- I have adjusted the RADI (Robotics Academy Docker Image) for the exercise to communicate with the docker:    
    - As a websocket is necessary for communication with webrtc, a new port has to be exposed in the docker, so that it is visible from outside. This is done by adding in the dockerfile:   
    ~~~
        EXPOSE <port>
    ~~~ 
    - It is also necessary to update the **manager.py** indicating the instructions for this exercise

- [Example video using WebRtc](https://youtu.be/arpt0t6tafQ)

### With Ros Node
- I have used a ros node that is responsible for publishing the frames obtained by the camera. And on the other hand, there is a consumer, who is in charge of collecting these frames and sending them to the browser via wesocket, so that it displays them.  
- I have also been exploring how to allow a docker to have access to the usb ports of the computer. This is possible by launching the following command when starting the container:   
  ~~~
    docker run -t -i  â€“privileged -v /dev/:/dev/ [nombre_contenedor] 
  ~~~

- Next steps to take:
    - Connect with the infrastructure of the exercise. Right now you only have the reading of images.   
    - Be able to run within the RADI
    
- [Example video of this first approach](https://youtu.be/vAK7J5RUmoM)

- References:
    - [https://automaticaddison.com/working-with-ros-and-opencv-in-ros-noetic/](https://automaticaddison.com/working-with-ros-and-opencv-in-ros-noetic/)  
    - [http://wiki.ros.org/video_stream_opencv](http://wiki.ros.org/video_stream_opencv)   
    - [http://wiki.ros.org/catkin/Tutorials/create_a_workspace](http://wiki.ros.org/catkin/Tutorials/create_a_workspace)   
    
### Unibotics

- I have delved into understanding the architecture and code of Unibotics. 

